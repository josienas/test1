# 專題需求對照與可行改進

根據投影片的專題要求，現有 Streamlit 範例程式（`app.py`）的狀況與缺漏如下：

## 目前狀況
- 僅有單支 Streamlit 程式，透過手動滑桿決定資料來源與超參數，缺乏自動化的 ETL/Pipeline 與排程機制。
- 資料收集與清洗集中在 `download_history` 與 `make_features_and_label` 之中，沒有拆出可重用的 DataOps 流程或紀錄資料品管結果。
- 模型訓練直接在前端即時執行，沒有持久化模型或紀錄版本，亦未整合 MLflow/Flask 進行服務化或部署。
- 缺少系統架構圖、資料流示意、以及模型訓練/部署的操作截圖與報告。

## 可依需求調整的方向
- **系統架構（ETL/Pipeline）**：
  - 拆分資料擷取、特徵工程、模型訓練為獨立模組，並以簡單的 CLI（如 `python btc_daily.py --interval 1h --output data/processed.csv`）或排程腳本自動化。
  - 繪製資料流與處理節點的架構圖，放入報告或 `README`。
- **DataOps（資料面）**：
  - 為原始/處理後資料加入品質檢查（筆數、缺失率、時間間隔檢查），並輸出檢查報告或日誌。
  - 儲存中間資料集（原始/清洗後/特徵後）以便重複使用與追蹤。
- **MLOps（模型面）**：
  - 將模型訓練包裝成腳本或 API，並用 MLflow/Flask 暴露推論端點；記錄訓練參數、指標與模型檔。
  - 產生並保存訓練與推論的螢幕截圖或執行記錄，滿足報告與 Demo 要求。
- **進階選項**：
  - 若時間允許，可加入 DVC 管理資料/模型版本，或撰寫 Dockerfile 讓整套服務可容器化部署。
- **評估報告**：
  - 提供完整的指標（準確率、混淆矩陣、ROC/PR 曲線）與錯誤案例分析，並整理成報告頁面或 Markdown。

以上調整能對應投影片列出的系統架構、DataOps、MLOps 以及可選的 DVC/Docker/LLMOps 項目。
